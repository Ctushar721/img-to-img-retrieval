{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8579230,"sourceType":"datasetVersion","datasetId":5130606}],"dockerImageVersionId":30715,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout, BatchNormalization, ReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import average_precision_score\nimport random\nimport os\nimport pandas as pd\nimport json\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\ndataset_dir = '/kaggle/input/img-to-img/human_activity_retrieval_dataset'\ninput_shape = (196, 196, 3)\nprint('step_done')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T20:31:15.971304Z","iopub.execute_input":"2024-06-02T20:31:15.971711Z","iopub.status.idle":"2024-06-02T20:31:15.980082Z","shell.execute_reply.started":"2024-06-02T20:31:15.971679Z","shell.execute_reply":"2024-06-02T20:31:15.978562Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"step_done\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create the base network (Siamese Network)\ndef create_base_network():\n    inp = Input(shape=input_shape)\n    x = Conv2D(32, (3, 3), activation='relu')(inp)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(64, (3, 3), activation='relu')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(128, (3, 3), activation='relu')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Flatten()(x)\n    output = Dense(128, activation=None)(x)\n    # norm_embeddings = tf.nn.l2_normalize(x, axis=-1)\n    return Model(inp, output)\n\ndef create_base_network_2():\n    inputs = Input(shape=input_shape)\n    # First layer\n    x = Dense(512)(inputs)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    # Second layer\n    x = Dense(256)(x)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    \n    # Output layer\n    outputs = Dense(15)(x)  # Total 15 classes\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    \n    return model\n\nbase_network = create_base_network_2()\nprint('step_done')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T20:31:42.317180Z","iopub.execute_input":"2024-06-02T20:31:42.317583Z","iopub.status.idle":"2024-06-02T20:31:42.389552Z","shell.execute_reply.started":"2024-06-02T20:31:42.317552Z","shell.execute_reply":"2024-06-02T20:31:42.388225Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"step_done\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_generator(dir_path, info_path, batch_size = 1, limit_per_demographic = 10):\n\n    # Define mapping from categories to numerical values\n    category_mapping = {'calling': 1, 'clapping': 2, 'cycling': 3, 'dancing': 4, 'drinking': 5, 'eating': 6,\n                        'fighting': 7, 'hugging': 8, 'laughing': 9, 'listening_to_music': 10, 'running': 11,\n                        'sitting': 12, 'sleeping': 13, 'texting': 14,\n                        'using_laptop': 15}\n    # Load image-to-label mappings\n    with open(info_path) as f:\n        info_map = json.load(f)\n    # Convert categories to numerical values in the JSON\n    info_map = {key: str(category_mapping[value]) for key, value in info_map.items()}\n    paths = []\n    labels_for_images = []\n    demographic_map = {}\n    final_map = {}\n    for file_name in sorted(info_map.keys()):\n        if info_map[file_name] in demographic_map:\n            demographic_map[info_map[file_name]] += 1\n        else:\n            demographic_map[info_map[file_name]] = 1\n            final_map[info_map[file_name]] = 0\n        if final_map[info_map[file_name]] >= limit_per_demographic:\n            continue\n\n        file_path = os.path.join(dir_path, file_name)\n        if os.path.isfile(file_path):\n            paths.append(file_path)\n            labels_for_images.append(info_map[file_name])\n            final_map[info_map[file_name]] += 1\n\n    print(final_map)\n    img_datagen = ImageDataGenerator(\n        featurewise_center=True,\n        horizontal_flip=False,\n        vertical_flip=False,\n        preprocessing_function=None,\n        data_format=None,\n        dtype=None)\n\n    train_df = pd.DataFrame({'filename': paths, 'label': labels_for_images})\n    width = 196\n    height = 196\n    # Data preprocessing and augmentation\n    generator = img_datagen.flow_from_dataframe(\n        dataframe=train_df,\n        directory=dir_path,\n        x_col='filename',\n        y_col='label',\n        target_size=(height, width),\n        batch_size=batch_size,\n        class_mode='categorical',\n        interpolation=\"nearest\",\n        shuffle=False\n    )\n    return generator, paths\n\n\ndef get_train_generator(limit_per_demographic = 10):\n    train_dir = os.path.join(dataset_dir, 'train')  # train\n    train_info_path = os.path.join(dataset_dir, 'train_image_info.json')  # train\n    return get_generator(train_dir, train_info_path, 32, limit_per_demographic)\ntrain_generator, image_paths = get_train_generator(50)\nprint('step_done', len(image_paths))\nprint(image_paths[:3])","metadata":{"execution":{"iopub.status.busy":"2024-06-02T20:31:48.204186Z","iopub.execute_input":"2024-06-02T20:31:48.204680Z","iopub.status.idle":"2024-06-02T20:31:49.399849Z","shell.execute_reply.started":"2024-06-02T20:31:48.204641Z","shell.execute_reply":"2024-06-02T20:31:49.398491Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'12': 50, '4': 50, '7': 50, '15': 50, '9': 50, '10': 50, '14': 50, '6': 50, '2': 50, '3': 50, '5': 50, '13': 50, '1': 50, '8': 50, '11': 50}\nFound 750 validated image filenames belonging to 15 classes.\nstep_done 750\n['/kaggle/input/img-to-img/human_activity_retrieval_dataset/train/Image_1.jpg', '/kaggle/input/img-to-img/human_activity_retrieval_dataset/train/Image_10.jpg', '/kaggle/input/img-to-img/human_activity_retrieval_dataset/train/Image_100.jpg']\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_pairs(image_paths, image_data, labels):\n    img_pairs = []\n    labels_pair = []\n    similar_img_path_pairs = []\n    dissimilar_img_path_pairs = []\n    num_classes = len(np.unique(labels))\n    class_indices = [np.where(labels == i)[0] for i in range(num_classes)]\n\n    for idx1 in range(len(image_data)):\n        current_image = image_data[idx1]\n        label = labels[idx1]\n\n        # Create positive pair\n        idx2 = random.choice(class_indices[label])\n        while idx1 == idx2:\n            idx2 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx2]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx2]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx3 = random.choice(class_indices[label])\n        while idx1 == idx3:\n            idx3 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx3]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx3]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx4 = random.choice(class_indices[label])\n        while idx1 == idx4:\n            idx4 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx4]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx4]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx5 = random.choice(class_indices[label])\n        while idx1 == idx5:\n            idx5 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx5]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx5]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx6 = random.choice(class_indices[label])\n        while idx1 == idx6:\n            idx6 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx6]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx5]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx7 = random.choice(class_indices[label])\n        while idx1 == idx7:\n            idx7 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx7]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx7]]]\n        labels_pair += [1]\n        \n        # Create positive pair\n        idx8 = random.choice(class_indices[label])\n        while idx1 == idx8:\n            idx8 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx8]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx8]]]\n        labels_pair += [1]\n\n        # Create positive pair\n        idx9 = random.choice(class_indices[label])\n        while idx1 == idx9:\n            idx9 = random.choice(class_indices[label])\n        img_pairs += [[current_image, image_data[idx9]]]\n        similar_img_path_pairs += [[image_paths[idx1], image_paths[idx9]]]\n        labels_pair += [1]\n        \n        # Create negative pair\n        neg_label = random.randint(0, num_classes - 1)\n        while neg_label == label:\n            neg_label = random.randint(0, num_classes - 1)\n        idx2 = random.choice(class_indices[neg_label])\n        img_pairs += [[current_image, image_data[idx2]]]\n        dissimilar_img_path_pairs += [[image_paths[idx1], image_paths[idx2]]]\n        labels_pair += [0]\n\n        neg_label2 = random.randint(0, num_classes - 1)\n        while neg_label2 == label:\n            neg_label2 = random.randint(0, num_classes - 1)\n        idx2 = random.choice(class_indices[neg_label2])\n        img_pairs += [[current_image, image_data[idx2]]]\n        dissimilar_img_path_pairs += [[image_paths[idx1], image_paths[idx2]]]\n        labels_pair += [0]\n        \n        neg_label3 = random.randint(0, num_classes - 1)\n        while neg_label3 == label:\n            neg_label3 = random.randint(0, num_classes - 1)\n        idx2 = random.choice(class_indices[neg_label3])\n        img_pairs += [[current_image, image_data[idx2]]]\n        dissimilar_img_path_pairs += [[image_paths[idx1], image_paths[idx2]]]\n        labels_pair += [0]\n        \n        neg_label4 = random.randint(0, num_classes - 1)\n        while neg_label4 == label:\n            neg_label4 = random.randint(0, num_classes - 1)\n        idx2 = random.choice(class_indices[neg_label4])\n        img_pairs += [[current_image, image_data[idx2]]]\n        dissimilar_img_path_pairs += [[image_paths[idx1], image_paths[idx2]]]\n        labels_pair += [0]\n\n    return np.array(img_pairs), np.array(labels_pair)\n\ndef get_train_images_and_labels():\n    # Prepare data for training\n    images, labels = [], []\n\n    for _ in range(len(train_generator)):\n        batch = next(train_generator)\n        images.extend(batch[0])\n        labels.extend(batch[1])\n\n    images = np.array(images)\n    labels = np.argmax(labels, axis=1)\n    print('images_len', len(images))\n    print('labels_len', len(labels))\n    final_pairs, final_labels = create_pairs(image_paths, images, labels)\n#     np.save('/kaggle/working/final_pairs_query.npy', final_pairs)\n#     np.save('/kaggle/working/final_labels_query.npy', final_labels)\n    return final_pairs, final_labels\npairs, labels = get_train_images_and_labels()\nprint('step_done')\nprint('labels_len', len(labels))\nprint('pairs_len', len(pairs))","metadata":{"execution":{"iopub.status.busy":"2024-06-02T20:32:01.683219Z","iopub.execute_input":"2024-06-02T20:32:01.683596Z","iopub.status.idle":"2024-06-02T20:32:08.913818Z","shell.execute_reply.started":"2024-06-02T20:32:01.683570Z","shell.execute_reply":"2024-06-02T20:32:08.912396Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"images_len 750\nlabels_len 750\nstep_done\nlabels_len 9000\npairs_len 9000\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer\n@tf.keras.utils.register_keras_serializable(package='Custom')\ndef euclidean_distance(vectors):\n    (featsA, featsB) = vectors\n    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n\n@tf.keras.utils.register_keras_serializable(package='Custom')\ndef contrastive_loss(y_true, y_pred, margin=1.0):\n    square_pred = tf.square(y_pred)\n    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n\n# Custom L2 Normalization Layer\n@tf.keras.utils.register_keras_serializable(package='Custom')\nclass L2Normalization(Layer):\n    def call(self, inputs):\n        return tf.nn.l2_normalize(inputs, axis=-1)\n@tf.keras.utils.register_keras_serializable(package='Custom')\nclass EuclideanDistance(Layer):\n    def call(self, inputs):\n        featsA, featsB = inputs\n        sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n        return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n\ndef train_model():\n    input_a = Input(shape=input_shape)\n    input_b = Input(shape=input_shape)\n\n    processed_a = base_network(input_a)\n    processed_b = base_network(input_b)\n    processed_a = L2Normalization()(processed_a)\n    processed_b = L2Normalization()(processed_b)\n    distance = EuclideanDistance()([processed_a, processed_b])\n\n    model = Model([input_a, input_b], distance)\n    optimizer = Adam(learning_rate=0.001)\n    model.compile(loss=contrastive_loss, optimizer=optimizer, metrics=['accuracy'])\n\n    \n#     pairs = np.load('/kaggle/working/final_pairs_full.npy')\n#     labels = np.load('/kaggle/working/final_labels_full.npy')\n\n    # Train the model\n    model.fit([pairs[:, 0], pairs[:, 1]], labels, batch_size=32, epochs=5)\n#     model.eval()\n    model.save('/kaggle/working/siamese_contrastive_full11.keras')\n    print('done')\n\nif __name__ == '__main__':\n    train_model()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T20:32:29.501536Z","iopub.execute_input":"2024-06-02T20:32:29.501963Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"}]}]}